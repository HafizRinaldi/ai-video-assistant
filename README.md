# **ü§ñ AI Video Assistant (Local RAG Version)**

This project is a powerful, self-hosted AI assistant that can index video content and answer natural language questions about it. It is built using a **Retrieval-Augmented Generation (RAG)** pipeline, leveraging powerful open-source models from Hugging Face, including the **Llama 3 Large Language Model (LLM)**, to provide a fully private, GPU-accelerated, and cost-free question-answering experience.  
The application features a modern web interface built with FastAPI and Tailwind CSS, allowing users to easily upload videos, view the full transcript, and interact with the AI.

## **‚ú® Features**

* **Video Indexing**: Process any .mp4 video file to create a searchable semantic index of its spoken content.  
* **Intelligent Question Answering**: Ask questions in plain English about the video's content and receive accurate, context-aware answers generated by a powerful Large Language Model.  
* **Interactive UI**: A clean, dashboard-style web interface for uploading videos, viewing transcripts, and interacting with the AI.  
* **Full Transcript Display & Download**: View the complete, timestamped transcript directly in the UI or download it as a .txt file.  
* **GPU Accelerated**: Automatically utilizes NVIDIA GPUs via PyTorch and CUDA for significantly faster transcription and answer generation.  
* **100% Local & Private**: Runs entirely on your local machine. Your videos and data are never sent to a third-party service, ensuring complete privacy and zero API costs.

## **üì∏ Screenshot**

Here is a preview of the application's user interface:

## **üõ†Ô∏è Technology Stack**

This project combines several state-of-the-art technologies from the Python AI ecosystem.

* **Backend**: FastAPI, Uvicorn  
* **Frontend**: HTML, Tailwind CSS, JavaScript  
* **AI Models (Hugging Face)**:  
  * **Transcription**: openai/whisper-base for converting speech to text with timestamps.  
  * **Embeddings**: sentence-transformers/all-MiniLM-L6-v2 for creating semantic vector representations of text.  
  * **Generative AI**: meta-llama/Meta-Llama-3-8B-Instruct for understanding context and generating answers.  
* **Core AI Libraries**: transformers, torch, sentence-transformers, accelerate  
* **Vector Database**: faiss-cpu / faiss-gpu for efficient similarity search.  
* **Video/Audio Processing**: ffmpeg-python

## **üöÄ Setup and Installation**

Follow these steps to get the project running on your local machine.

### **Prerequisites**

* Python 3.9+  
* An **NVIDIA GPU** with CUDA installed is highly recommended for acceptable performance.  
* **FFMPEG** installed and added to your system's PATH environment variable.

### **Installation Steps**

1. **Clone the repository:**  
   git clone https://github.com/YOUR\_USERNAME/ai-video-assistant.git  
   cd ai-video-assistant

2. **Create and activate a virtual environment:**  
   \# Create the environment  
   python \-m venv venv  
   \# Activate on Windows  
   venv\\Scripts\\activate  
   \# Activate on macOS/Linux  
   \# source venv/bin/activate

3. **Install all required libraries:**  
   * First, install PyTorch with CUDA support. Go to the [PyTorch website](https://pytorch.org/get-started/locally/) to get the correct command for your CUDA version. For example:  
     pip install torch torchvision torchaudio \--index-url https://download.pytorch.org/whl/cu121

   * Then, install the rest of the packages from the requirements.txt file:  
     pip install \-r requirements.txt

4. **Set up your environment variables:**  
   * Create a file in the root directory named .env.  
   * Add your Hugging Face Access Token to it. You need this to download the Llama 3 model.  
     HUGGING\_FACE\_TOKEN="hf\_..."

5. **Log in to Hugging Face:**  
   * Run this command in your terminal and paste your token when prompted.

huggingface-cli login

## **‚öôÔ∏è How to Use**

### **1\. Run the Server**

Start the FastAPI server from your terminal (make sure your virtual environment is active):  
uvicorn main:app \--reload

### **2\. Open the Application**

Open your web browser and navigate to **http://1227.0.0.1:8000**.

### **3\. Index a Video**

* In the web UI, click "Choose File" and select an .mp4 video.  
* Click the "Unggah & Indeks Video" button.  
* Wait for the indexing process to complete. This can take a long time depending on the video length and your hardware. The full transcript will appear on the right-hand panel when finished.

### **4\. Ask a Question**

* Once indexing is complete, the question input box will appear.  
* Type your question about the video's content and click "Tanyakan pada AI".  
* The AI's answer will appear below the input box.
